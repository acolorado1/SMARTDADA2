{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## What to consider\n",
    "\n",
    "There is a tradeoff between *Quantity*, *Quality*, and the *number of retained reads* that will remain after quality control. This program\n",
    "will attempt to balance these three variables and provide the user with potential combinations of DADA2 parameters.\n",
    "\n",
    "In this case both **trimming** and **maxEE** will be DADA2 parameters that we focus on.\n",
    "\n",
    "### How to do this:\n",
    "\n",
    "1. Perform \"obvious\" trimming\n",
    "    + iterate along the average quality score and eliminate ends below a threshold (default will be 30)\n",
    "\n",
    "2. Examining the relationship between trim values/read length and quality \n",
    "    + Understanding the effect that different trim values has on the overall quality of the reads \n",
    "    + Plot generated will provide empirical proof for parameter choice  \n",
    "\n",
    "3. Examining the relationnship between trim values and retained reads\n",
    "    + maxEE is a DADA2 parameter wherein if the sum of the read's expected error (per position) is higher than this threshold (default = 2.0) the read will be discarded. This automatically penalized longer reads.\n",
    "    + Here we show the effect that maxEE will have on reads that have not been trimmed and reads that have only been trimmed using the \"obvious\" trimming values. \n",
    "\n",
    "\n",
    "## Performing \"Obvious\" Trimming\n",
    "\n",
    "Current industry standards involve looking at a barplot and picking trim values where a noticeable decrease in average\n",
    "quality score at a position on either end of the read occurs. Here we start with the same concept in order to reduce\n",
    "search space.\n",
    "\n",
    "The trim values (or index at which trimming is done) is determined by the first instance an average quality score is\n",
    "below a threshold starting from the center index. This is done because the highest quality scores will be in the middle\n",
    "of the reads.\n",
    "\n",
    "It is also important to note that scores, as output in FASTQ files, are on a scale from 0 to 42 as per Phred quality\n",
    "score standards.\n",
    "\n",
    "Here is a step-by-step process of how this form of trimming is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: set threshold value\n",
    "threshold = 30\n",
    "\n",
    "# Step 2: middle index is determined\n",
    "list = [15, 18, 18, 30, 30, 40, 30, 30, 19, 17, 15]\n",
    "\n",
    "mid_index = len(list) // 2\n",
    "\n",
    "# Step 3: travel from center to left and find instance of average score below threshold\n",
    "current_index = mid_index\n",
    "while current_index >= 0:\n",
    "    # if value at current index is below threshold\n",
    "    if list[current_index] < threshold:\n",
    "        # get the prior index\n",
    "        trim_left_index = current_index + 1\n",
    "        break\n",
    "    else:\n",
    "        current_index -= 1\n",
    "\n",
    "# Step 4: similar to step 3 the right index value is found\n",
    "\n",
    "# Step 5: tuple containing left and right trim sites is returned. For the list in this example, the returned value\n",
    "# would be (3, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Length vs Quality\n",
    "\n",
    "A tsv is generated using **GetTrimParameters.py** wherein different index combinations were chosen and the average expected error per position along the read was calculated. \n",
    "\n",
    "The average expected error per positon was first calculated using the FastqEntry function **get_expected_error()**. Using different combinations of trim parameters the avergae was taken of those averages to get an overall average expected error per position and a heat map was generated using R. In addition a plot wherein the x axis is read length and the y axis is average expected error per position was created to juxtapose these specific variable and further inform the user of the potential effect that different trim, truncation, and read lengths would have on the overall quality of the reads and samples. \n",
    "\n",
    "Note: it is important to understand that there will be multiple combinations of index pairs with the same read length. For examples, if you indexed a read from 0 to 10 it would result in a read of the same length if you had indexed it from 1 to 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Length vs Number of Retained Reads\n",
    "Overall it is impossible to calculate exactly how many reads will be discarded during quality control. However, you can see the effect that different trimming might have on the number of reads that fall above a max expected error threshold (set by DADA2). \n",
    "\n",
    "Here we show how many reads will be discarded should no trimming occur and how many reads will be discarded should only obvious trimming occur. This was done using a histogram in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
